{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Tool using RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build Advanced RAG Pipeline With Multiple Data Sources such as arxiv,wikipedia and our custom web source .Here we will be using agents,tools,toolkits and agent executor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools in LangChain,\n",
    "Langchain Tools are interfaces that an agent, chain, or LLM can use to interact with the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this RAG application we will create 3 tools usng Arxiv, Wikipedia, and our own custom web source, combinig these tools we will create a RAG pipeline and use a conversational retrieval agent to ask questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at how to work with tools. To do this, we'll work with a built in tool.\n",
    "\n",
    "## Wikipedia\n",
    "\n",
    "We will create a wrapper on top is wikipedia. The WikipediaQueryRun tool connects your agents and chains to Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arxiv Tool\n",
    "\n",
    "Langchain inbuilt arXiv is an open-access archive for 2 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in c:\\users\\d41284976\\desktop\\research tool rag\\venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in c:\\users\\d41284976\\desktop\\research tool rag\\venv\\lib\\site-packages (from arxiv) (6.0.11)\n",
      "Requirement already satisfied: requests~=2.32.0 in c:\\users\\d41284976\\desktop\\research tool rag\\venv\\lib\\site-packages (from arxiv) (2.32.3)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\d41284976\\desktop\\research tool rag\\venv\\lib\\site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\d41284976\\desktop\\research tool rag\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\d41284976\\desktop\\research tool rag\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\d41284976\\desktop\\research tool rag\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\d41284976\\desktop\\research tool rag\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2024.7.4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Arxiv Tool\n",
    "!pip install arxiv\n",
    "\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Web based tool.\n",
    "\n",
    "We will use a custom web page from LangChain documentation to add into our pipeline. We will use WebBaseLoader to ingest data from the web, then perform techniques like Chunking and Embeddings to create our app. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking.\n",
    "\n",
    "We used RecursiveCharacterTextSplitter to create chunks or our text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings.\n",
    "\n",
    "We will use OllamaEmbeddings to convert chunks into vector embeddings the store those vectors in a vector store called FAISS vector Db. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001F5EE790640>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectordb=FAISS.from_documents(documents,OllamaEmbeddings())\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using agents\n",
    "\n",
    "This is an agent specifically optimized for doing retrieval when necessary and also holding a conversation.\n",
    "\n",
    "To start, we have set up the retriever we want to use, and then turn it into a retriever tool. Next, we will use the high level constructor for this type of agent.\n",
    "\n",
    "### Retriever Tool\n",
    "\n",
    "Now we need to create a tool for our retriever. The main things we need to pass in are a name for the retriever as well as a description. These will both be used by the language model, so they should be informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith_search\",\n",
    "                      \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Tool\n",
    "\n",
    "Now we will compile our 3 tools to create a combines Research Tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki, arxiv, retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started with executing agents we will assign our LLM and prompts using promp_hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv(\"LANGCHAIN_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "The core idea of agents is to use a language model to choose a sequence of actions to take. In chains, a sequence of actions is hardcoded (in code). In agents, a language model is used as a reasoning engine to determine which actions to take and in which order.\n",
    "\n",
    "For our Reseach Tool, a user will input a query and our application will use agents to fetch the results in order. Firstly it will look into Wikipedia if not found then arxiv and later in the web source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent=create_openai_tools_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOllama(model='llama3'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\D41284976\\\\Desktop\\\\Research Tool RAG\\\\venv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200, arxiv_result=<class 'arxiv.Result'>)), Tool(name='langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001F5A7996F80>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001F5EE790640>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001F5A7997130>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001F5EE790640>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLangsmith!\n",
      "\n",
      "Langsmith is a small hamlet located in the county of Gloucestershire, England. It's a tiny settlement with a population of less than 100 people. Despite its size, Langsmith has a rich history and some interesting facts worth sharing:\n",
      "\n",
      "1. **Historic church**: Langsmith has an ancient church, St Mary's, which dates back to the 12th century. The church is known for its unique architecture and stunning stained-glass windows.\n",
      "2. **Roman roots**: Archaeological findings suggest that Langsmith was an important Roman settlement, with evidence of Roman roads and buildings in the area.\n",
      "3. **Agricultural heritage**: For centuries, Langsmith has been an agricultural hub, with farming being a significant part of its economy. The surrounding countryside is still used for arable farming and livestock rearing.\n",
      "4. **Community spirit**: Despite its small size, Langsmith has a strong sense of community, with many locals actively involved in local events and initiatives.\n",
      "5. **Scenic location**: Langsmith is situated in the Cotswolds Area of Outstanding Natural Beauty (AONB), making it an ideal base for exploring the picturesque countryside.\n",
      "\n",
      "Langsmith might be a small village, but its history, culture, and natural beauty make it a charming destination worth visiting!\n",
      "\n",
      "Would you like to know more about Langsmith or explore related topics?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': \"Langsmith!\\n\\nLangsmith is a small hamlet located in the county of Gloucestershire, England. It's a tiny settlement with a population of less than 100 people. Despite its size, Langsmith has a rich history and some interesting facts worth sharing:\\n\\n1. **Historic church**: Langsmith has an ancient church, St Mary's, which dates back to the 12th century. The church is known for its unique architecture and stunning stained-glass windows.\\n2. **Roman roots**: Archaeological findings suggest that Langsmith was an important Roman settlement, with evidence of Roman roads and buildings in the area.\\n3. **Agricultural heritage**: For centuries, Langsmith has been an agricultural hub, with farming being a significant part of its economy. The surrounding countryside is still used for arable farming and livestock rearing.\\n4. **Community spirit**: Despite its small size, Langsmith has a strong sense of community, with many locals actively involved in local events and initiatives.\\n5. **Scenic location**: Langsmith is situated in the Cotswolds Area of Outstanding Natural Beauty (AONB), making it an ideal base for exploring the picturesque countryside.\\n\\nLangsmith might be a small village, but its history, culture, and natural beauty make it a charming destination worth visiting!\\n\\nWould you like to know more about Langsmith or explore related topics?\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe paper you're referring to is titled \"Attention Is All You Need\" and has the arXiv identifier 1605.08386.\n",
      "\n",
      "This paper, published in 2017, revolutionized the field of natural language processing (NLP) by introducing a new architecture for neural machine translation called Transformer. The authors, Ashish Vaswani et al., proposed a novel approach that relies solely on self-attention mechanisms, eliminating the need for traditional recurrent and convolutional neural networks (RNNs/CNNs).\n",
      "\n",
      "The paper's main contribution is the Transformer model, which consists of an encoder and a decoder. The encoder transforms input sequences into continuous representations, while the decoder generates output sequences by attending to these representations. This self-attention mechanism allows the model to process input sequences in parallel, making it more efficient than traditional sequence-to-sequence models that rely on RNNs.\n",
      "\n",
      "The paper presents experiments demonstrating the effectiveness of the Transformer model for machine translation tasks, achieving state-of-the-art results on several benchmarks at the time. Since then, the Transformer architecture has become widely adopted in many NLP applications, including language translation, text generation, and question answering.\n",
      "\n",
      "Overall, \"Attention Is All You Need\" is a seminal paper that has had a significant impact on the development of deep learning models for sequence processing tasks.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the paper 1605.08386 about?\",\n",
       " 'output': 'The paper you\\'re referring to is titled \"Attention Is All You Need\" and has the arXiv identifier 1605.08386.\\n\\nThis paper, published in 2017, revolutionized the field of natural language processing (NLP) by introducing a new architecture for neural machine translation called Transformer. The authors, Ashish Vaswani et al., proposed a novel approach that relies solely on self-attention mechanisms, eliminating the need for traditional recurrent and convolutional neural networks (RNNs/CNNs).\\n\\nThe paper\\'s main contribution is the Transformer model, which consists of an encoder and a decoder. The encoder transforms input sequences into continuous representations, while the decoder generates output sequences by attending to these representations. This self-attention mechanism allows the model to process input sequences in parallel, making it more efficient than traditional sequence-to-sequence models that rely on RNNs.\\n\\nThe paper presents experiments demonstrating the effectiveness of the Transformer model for machine translation tasks, achieving state-of-the-art results on several benchmarks at the time. Since then, the Transformer architecture has become widely adopted in many NLP applications, including language translation, text generation, and question answering.\\n\\nOverall, \"Attention Is All You Need\" is a seminal paper that has had a significant impact on the development of deep learning models for sequence processing tasks.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What's the paper 1605.08386 about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mWhile it's true that AI has the potential to automate certain tasks and potentially replace some jobs, I'd like to focus on the many ways you can leverage AI to grow your career, business, or personal life.\n",
      "\n",
      "Here are some examples of how AI can help:\n",
      "\n",
      "1. **Process Automation**: Focus on high-value tasks that require human judgment, creativity, and empathy, while leaving repetitive, routine tasks to AI-powered tools.\n",
      "2. **Data Analysis**: Leverage AI-driven analytics platforms to gain insights from large datasets, identify trends, and make data-informed decisions.\n",
      "3. **Customer Service**: Implement AI-powered chatbots or virtual assistants to handle common customer inquiries, freeing up your time for more complex issues.\n",
      "4. **Marketing Automation**: Use AI-driven marketing tools to personalize content, segment audiences, and optimize campaigns based on user behavior.\n",
      "5. **Content Creation**: Utilize AI-generated content, such as articles, social media posts, or even entire books, to amplify your reach and reduce the workload.\n",
      "6. **Virtual Collaboration**: Attend virtual meetings, participate in online training sessions, or collaborate with remote teams using AI-powered tools that facilitate seamless communication.\n",
      "7. **Skill Development**: Take advantage of AI-driven learning platforms, which can help you upskill or reskill in areas like programming, data science, or digital marketing.\n",
      "8. **Business Intelligence**: Use AI-powered business intelligence solutions to gain a deeper understanding of your market, competitors, and customers.\n",
      "9. **Time Management**: Implement AI-driven calendar and scheduling tools to optimize your time, reduce meetings, and increase productivity.\n",
      "10. **Personalized Recommendations**: Leverage AI-generated content recommendations to discover new books, music, or movies tailored to your interests.\n",
      "\n",
      "To get started with using AI to grow:\n",
      "\n",
      "1. Identify areas where you'd like to leverage AI (e.g., marketing automation, data analysis, or process optimization).\n",
      "2. Research and experiment with different AI tools and platforms that align with your goals.\n",
      "3. Develop a solid understanding of the AI technology and its limitations.\n",
      "4. Start small and scale up as you gain experience and confidence.\n",
      "5. Continuously learn from your experiences and adapt to changing AI technologies.\n",
      "\n",
      "By embracing AI and focusing on high-value tasks, you can grow your career or business while augmenting human capabilities with machine intelligence.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Is AI going to take jobs, tell me how to use AI to grow?',\n",
       " 'output': \"While it's true that AI has the potential to automate certain tasks and potentially replace some jobs, I'd like to focus on the many ways you can leverage AI to grow your career, business, or personal life.\\n\\nHere are some examples of how AI can help:\\n\\n1. **Process Automation**: Focus on high-value tasks that require human judgment, creativity, and empathy, while leaving repetitive, routine tasks to AI-powered tools.\\n2. **Data Analysis**: Leverage AI-driven analytics platforms to gain insights from large datasets, identify trends, and make data-informed decisions.\\n3. **Customer Service**: Implement AI-powered chatbots or virtual assistants to handle common customer inquiries, freeing up your time for more complex issues.\\n4. **Marketing Automation**: Use AI-driven marketing tools to personalize content, segment audiences, and optimize campaigns based on user behavior.\\n5. **Content Creation**: Utilize AI-generated content, such as articles, social media posts, or even entire books, to amplify your reach and reduce the workload.\\n6. **Virtual Collaboration**: Attend virtual meetings, participate in online training sessions, or collaborate with remote teams using AI-powered tools that facilitate seamless communication.\\n7. **Skill Development**: Take advantage of AI-driven learning platforms, which can help you upskill or reskill in areas like programming, data science, or digital marketing.\\n8. **Business Intelligence**: Use AI-powered business intelligence solutions to gain a deeper understanding of your market, competitors, and customers.\\n9. **Time Management**: Implement AI-driven calendar and scheduling tools to optimize your time, reduce meetings, and increase productivity.\\n10. **Personalized Recommendations**: Leverage AI-generated content recommendations to discover new books, music, or movies tailored to your interests.\\n\\nTo get started with using AI to grow:\\n\\n1. Identify areas where you'd like to leverage AI (e.g., marketing automation, data analysis, or process optimization).\\n2. Research and experiment with different AI tools and platforms that align with your goals.\\n3. Develop a solid understanding of the AI technology and its limitations.\\n4. Start small and scale up as you gain experience and confidence.\\n5. Continuously learn from your experiences and adapt to changing AI technologies.\\n\\nBy embracing AI and focusing on high-value tasks, you can grow your career or business while augmenting human capabilities with machine intelligence.\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Is AI going to take jobs, tell me how to use AI to grow?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
